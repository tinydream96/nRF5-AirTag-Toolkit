# 数据点去重逻辑修改记录

## 问题描述
- **原始问题**：71个位置报告被压缩成只有1个位置点
- **数据特征**：所有位置报告都有相同的时间戳（1752940870967），但存在微小的坐标差异
- **期望结果**：保留有意义的位置差异，去除真正的重复数据

## 修改前的逻辑

### 原始去重函数 `_is_duplicate_location`
```python
def _is_duplicate_location(self, point1: Dict[str, Any], point2: Dict[str, Any]) -> bool:
    """判断两个位置点是否重复（原始逻辑）"""
    # 时间差检查
    try:
        time1 = datetime.fromisoformat(point1["timestamp"].replace("Z", "+00:00"))
        time2 = datetime.fromisoformat(point2["timestamp"].replace("Z", "+00:00"))
        time_diff = abs((time1 - time2).total_seconds())

        # 如果时间差小于容差，检查位置是否相近
        if time_diff <= Config.LOCATION_TIME_TOLERANCE:  # 30秒
            lat1, lon1 = point1["latitude"], point1["longitude"]
            lat2, lon2 = point2["latitude"], point2["longitude"]

            # 计算距离（米）
            distance = calculate_distance(lat1, lon1, lat2, lon2)

            # 如果距离小于5米且时间相近，认为是重复
            if distance < 5:
                return True
    except (ValueError, KeyError):
        # 如果时间解析失败，使用简单的签名比较
        pass

    # 使用签名比较
    return self._create_location_signature(point1) == self._create_location_signature(point2)
```

### 原始签名创建函数 `_create_location_signature`
```python
def _create_location_signature(self, point: Dict[str, Any]) -> str:
    """创建位置点的唯一签名，用于去重"""
    # 使用时间戳和坐标创建签名
    timestamp = point.get("timestamp", "")
    lat = point.get("latitude", 0)
    lon = point.get("longitude", 0)

    # 坐标精确到配置的精度（默认6位小数，约1米精度）
    precision = Config.LOCATION_DEDUP_PRECISION  # 6
    return f"{timestamp}_{lat:.{precision}f}_{lon:.{precision}f}"
```

### 原始配置
```python
LOCATION_TIME_TOLERANCE = 30  # 30秒
LOCATION_DEDUP_PRECISION = 6  # 6位小数精度
```

## 修改后的逻辑

### 新的去重函数 `_is_duplicate_location`
```python
def _is_duplicate_location(self, point1: Dict[str, Any], point2: Dict[str, Any]) -> bool:
    """判断两个位置点是否重复（更宽松的去重逻辑）"""
    try:
        # 首先检查时间戳是否完全相同
        if point1["timestamp"] == point2["timestamp"]:
            # 时间戳相同时，检查坐标是否完全相同
            lat1, lon1 = point1["latitude"], point1["longitude"]
            lat2, lon2 = point2["latitude"], point2["longitude"]
            
            # 计算坐标差异（使用更精确的比较）
            coord_diff = abs(lat1 - lat2) + abs(lon1 - lon2)
            self.logger.debug(f"📍 坐标比较: ({lat1:.7f}, {lon1:.7f}) vs ({lat2:.7f}, {lon2:.7f}), 差异={coord_diff:.8f}")
            
            # 只有坐标差异小于0.0000001度（约0.01米）才认为是重复
            if coord_diff < 0.0000001:
                self.logger.debug(f"🔄 发现完全重复位置: {point1['timestamp']} 差异{coord_diff:.8f}")
                return True
            else:
                self.logger.debug(f"✅ 时间相同但位置不同: 坐标差异{coord_diff:.8f}")
                return False
        
        # 时间戳不同的情况下，进行更严格的检查
        time1 = datetime.fromisoformat(point1["timestamp"].replace("Z", "+00:00"))
        time2 = datetime.fromisoformat(point2["timestamp"].replace("Z", "+00:00"))
        time_diff = abs((time1 - time2).total_seconds())

        # 只有在时间差很小（10秒内）且位置很近（1米内）时才认为是重复
        if time_diff <= 10:
            lat1, lon1 = point1["latitude"], point1["longitude"]
            lat2, lon2 = point2["latitude"], point2["longitude"]

            # 计算距离（米）
            distance = calculate_distance(lat1, lon1, lat2, lon2)

            # 如果距离小于1米且时间很近，认为是重复
            if distance < 1:
                self.logger.debug(f"🔄 发现近似重复位置: 时间差{time_diff:.1f}秒, 距离{distance:.1f}米")
                return True
        
        # 其他情况都不认为是重复
        return False
        
    except (ValueError, KeyError) as e:
        self.logger.debug(f"⚠️ 时间解析失败: {e}")
        return False
```

### 修改的配置
```python
LOCATION_TIME_TOLERANCE = 60  # 增加到60秒，避免过度去重
```

## 关键修改点

### 1. 时间戳处理策略
- **修改前**：统一使用时间差+距离判断
- **修改后**：分两种情况处理
  - 相同时间戳：只比较坐标精度
  - 不同时间戳：时间差+距离双重判断

### 2. 坐标精度阈值
- **修改前**：使用签名比较，精度为6位小数（约1米）
- **修改后**：直接数值比较，阈值为0.0000001度（约0.01米）

### 3. 距离判断阈值
- **修改前**：5米内认为重复
- **修改后**：1米内认为重复（仅用于不同时间戳的情况）

### 4. 时间容差
- **修改前**：30秒内+5米内认为重复
- **修改后**：10秒内+1米内认为重复（仅用于不同时间戳的情况）

### 5. 错误处理
- **修改前**：解析失败时使用签名比较作为后备
- **修改后**：解析失败时直接返回false，不认为重复

## 实际效果对比

### 测试数据特征
- 总位置报告：71个
- 时间戳：全部相同（1752940870967 -> 2025-07-20T00:01:10.967）
- 坐标范围：
  - 纬度：26.0137512 - 26.0137513
  - 经度：112.2870604 - 112.2870610
  - 最大坐标差异：约0.00000070度（约0.08米）

### 结果对比
- **修改前**：71个报告 → 1个位置点（过度去重）
- **修改后**：71个报告 → 4个位置点（合理去重）

### 去重统计
- **保留的4个位置点**：代表4个不同的微观位置
- **去除的67个重复点**：真正的完全重复数据
- **距离范围**：保留的点之间距离约0.01-0.08米

## 改进建议（供其他AI参考）

### 可能的优化方向

1. **动态阈值**：根据GPS精度动态调整去重阈值
2. **时间窗口**：考虑设备移动速度，动态调整时间容差
3. **聚类算法**：使用DBSCAN等聚类算法进行更智能的去重
4. **精度权重**：根据GPS精度值调整去重策略
5. **移动模式识别**：静止、步行、车辆等不同模式使用不同去重策略

### 潜在问题

1. **边界情况**：阈值边界附近的数据点可能处理不一致
2. **性能考虑**：大量数据时的计算效率
3. **精度损失**：浮点数比较的精度问题
4. **时区处理**：跨时区数据的时间戳处理

### 测试建议

1. **多样化数据**：测试不同GPS精度、不同移动模式的数据
2. **边界测试**：测试阈值边界附近的数据
3. **性能测试**：测试大量数据的处理性能
4. **回归测试**：确保修改不影响其他功能

## 代码位置

- **文件**：`get_tracks.py`
- **主要函数**：
  - `_is_duplicate_location` (行952-1003)
  - `_merge_location_data` (行880-919)
  - `_remove_internal_duplicates` (行921-939)
- **配置**：`Config.LOCATION_TIME_TOLERANCE` (行40)

## 测试命令

```bash
# 删除现有数据重新测试
rm -rf /Users/luo/Downloads/data/devices/R0VVSW/daily_tracks_2025-07-20.json

# 运行测试
python get_tracks.py

# 启用调试模式查看详细信息
# 修改 logger.setLevel(logging.DEBUG) 然后运行
```

---

**创建时间**：2025-07-20  
**修改者**：Rovo Dev AI  
**版本**：v1.0  
**目的**：为其他AI提供完整的修改记录和对比基准